{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1导入数据"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入库函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "labelDict = {'1': 0,'2':1,'3':2,'G11': 3,'G12':4,'G13':5}\n",
    "folders = glob.glob('indata/npy224/*')\n",
    "# 数据\n",
    "datas = []\n",
    "for i in range(6):\n",
    "    datas.append([])\n",
    "    pass\n",
    "\n",
    "# 载入数据\n",
    "for folder in folders:      \n",
    "    folder = folder.replace('\\\\', '/')\n",
    "    label = labelDict[folder.split('/')[-1].split('_')[0]]\n",
    "    # 数据提取\n",
    "    npys = glob.glob(folder + '/*.npy')\n",
    "    for npy in npys:\n",
    "        npy = npy.replace('\\\\', '/')\n",
    "        # data_npy = np.load(file=npy)\n",
    "        datas[label].append(npy)    \n",
    "        pass\n",
    "    pass\n",
    "datas\n",
    "datanp = np.array(datas)\n",
    "datanp.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分训练集合测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "# datanp=shuffle(datanp) \n",
    "train_data = []\n",
    "train_label = []\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "for label in range(6):\n",
    "    traindata,testdata = train_test_split(datanp[label],test_size=0.2,random_state=0,shuffle=True)\n",
    "    train_data.extend(traindata)\n",
    "    test_data.extend(testdata)\n",
    "    train_shape = np.array(traindata).shape\n",
    "    test_shape = np.array(testdata).shape\n",
    "    train_label.extend(np.full(train_shape,label))\n",
    "    test_label.extend(np.full(test_shape,label))\n",
    "     \n",
    "# train_data = np.array(train_data)\n",
    "# train_label = np.array(pd.get_dummies(train_label))\n",
    "# test_data = np.array(test_data)\n",
    "# test_label = np.array(pd.get_dummies(test_label))\n",
    "\n",
    "train_pd = pd.DataFrame(columns=['datapath','label'])\n",
    "test_pd = pd.DataFrame(columns=['datapath','label'])\n",
    "for i in range(0,len(train_data)):\n",
    "    train_pd = train_pd._append(pd.Series({'datapath':train_data[i],'label':train_label[i]}),ignore_index=True)\n",
    "    pass\n",
    "for i in range(0,len(test_data)):\n",
    "    test_pd = test_pd._append(pd.Series({'datapath':test_data[i],'label':test_label[i]}),ignore_index=True)\n",
    "    pass\n",
    "train_pd = shuffle(train_pd)\n",
    "test_pd = shuffle(test_pd)\n",
    "# train_pd = pd.concat([pd.DataFrame(train_data),pd.DataFrame(train_label)],axis=1)\n",
    "# test_pd = pd.concat([pd.DataFrame(test_data),pd.DataFrame(test_label)],axis=1)\n",
    "train_data = np.array(train_pd['datapath'])\n",
    "train_label = np.array(pd.get_dummies(train_pd['label']))\n",
    "test_data = np.array(test_pd['datapath'])\n",
    "test_label = np.array(pd.get_dummies(test_pd['label']))\n",
    "# test_label = np.array(test_label)\n",
    "# 训练模型\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入之前的训练集，测试集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=np.load(\"train_data.npy\",allow_pickle=True)\n",
    "test_data=np.load(\"test_data.npy\",allow_pickle=True)\n",
    "train_label=np.load(\"train_label.npy\",allow_pickle=True)\n",
    "test_label=np.load(\"test_label.npy\",allow_pickle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.concatenate((train_data, test_data), axis=0)\n",
    "targets = np.concatenate((train_label, test_label), axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "import keras\n",
    "import keras.callbacks\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    " \n",
    "\n",
    "def get_model2D(width=30, height=30, channel=224):\n",
    "    \"\"\"Build a 2D convolutional neural network model.\"\"\"\n",
    "    inputs = keras.Input((width, height, channel))\n",
    "    # aver=tf.reduce_mean(inputs,axis=0)\n",
    "    # aver1=tf.reduce_mean(aver,axis=1)\n",
    "    # aver1=tf.reduce_mean(aver1,axis=0)\n",
    "    # print(aver1.shape)\n",
    "    # aver2=layers.Dense(units=54)(aver1)\n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, strides=1,kernel_regularizer=regularizers.L1(0.003))(inputs)  #激活函数要不要改成热炉\n",
    "    x= layers.Conv2D( filters=64,kernel_size=3, strides=1,kernel_regularizer=regularizers.L2(0.003),activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(units=64,kernel_initializer=keras.initializers.glorot_uniform(seed=None))(x)  #图像 模型得到\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    outputs = layers.Dense(units=6,activation='softmax')(x)\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"2dcnn\")\n",
    "    return model\n",
    "# Build model.\n",
    "model = get_model2D(width=30, height=30, channel=224)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3训练前"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化/批处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "def get_train_batch_3D(x_train_paths, y_labels, batch_size):\n",
    "    '''\n",
    "    参数：\n",
    "        X_train：所有图片路径列表\n",
    "        y_train: 所有图片对应的标签列表\n",
    "        batch_size:批次\n",
    "        img_w:图片宽\n",
    "        img_h:图片高\n",
    "        color_type:图片类型\n",
    "        is_argumentation:是否需要数据增强\n",
    "    返回: \n",
    "        一个generator，x: 获取的批次图片 y: 获取的图片对应的标签\n",
    "    '''\n",
    "    while 1:\n",
    "        for i in range(0,len(x_train_paths),batch_size):\n",
    "            x_train = np.load(file=x_train_paths[i])\n",
    "            y_label = y_labels[i]\n",
    "\n",
    "            x_train[np.isinf(x_train)] = 0\n",
    "            x_train[np.isnan(x_train)] = 0\n",
    "\n",
    "            # x_train = np.expand_dims(x_train,axis=0)\n",
    "            # y_label = np.expand_dims(y_label,axis=0)           \n",
    "            # print(x_train.shape)\n",
    "            # print(y_label.shape)\n",
    "            yield(np.array(x_train), np.array(y_label))\n",
    "\n",
    "def get_train_batch_2D(x_train_paths, y_labels, batch_size):\n",
    "    '''\n",
    "    参数：\n",
    "        X_train：所有图片路径列表\n",
    "        y_train: 所有图片对应的标签列表\n",
    "        batch_size:批次\n",
    "        img_w:图片宽\n",
    "        img_h:图片高\n",
    "        color_type:图片类型\n",
    "        is_argumentation:是否需要数据增强\n",
    "    返回: \n",
    "        一个generator，x: 获取的批次图片 y: 获取的图片对应的标签\n",
    "    '''\n",
    "    while 1:\n",
    "        for i in range(0,len(x_train_paths),batch_size):\n",
    "            x_train = np.load(file=x_train_paths[i])\n",
    "            x_train = scaler.fit_transform(\n",
    "                 x_train.astype(np.float32).reshape(-1,1)).reshape(30, 30,224)\n",
    "            y_label = y_labels[i]\n",
    "            x_train[np.isinf(x_train)] = 0\n",
    "            x_train[np.isnan(x_train)] = 0\n",
    "            x_train = np.expand_dims(x_train,axis=0)\n",
    "            y_label = np.expand_dims(y_label,axis=0)\n",
    "            yield(np.array(x_train), np.array(y_label)) \n",
    "    print(\"finish\") \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "固定随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 固定 Python 随机种子\n",
    "random.seed(42)\n",
    "\n",
    "# 固定 Numpy 随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "# 固定 TensorFlow 随机种子\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4模型训练"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"425new-0.9-0.88\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(r'model_save\\84-90best511.h5 ') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一个，现在的模型有8层左右\n",
    "# 第一个，现在的模型有8层左右\n",
    "import keras.optimizers\n",
    "import keras.losses\n",
    "import keras.metrics\n",
    "import keras.callbacks\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "# lr=1e-3,decay=1e-6,momentum=0.9     lr=1e-3,decay=1e-6,momentum=0.9,nesterov=True, clipnorm=1.\n",
    "'''用不同的优化器训练模型'''\n",
    "rms=optimizers.rmsprop_v2.RMSProp(lr=0.0000015) \n",
    "sgd2=optimizers.gradient_descent_v2.SGD(lr=0.0000001,momentum=0.1,nesterov=True)\n",
    "adelta=optimizers.adadelta_v2.Adadelta(lr=0.00001)\n",
    "adam=keras.optimizers.adam_v2.Adam(lr=0.000000001)\n",
    "\n",
    "'''自动保存最优模型'''\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('./model_save/best.h5', monitor='val_acc', verbose=0,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=False, mode='max',\n",
    "                                period=1)\n",
    "'''设置早停'''\n",
    "earlyStop = EarlyStopping(monitor='val_acc', min_delta=0.003, patience=20, mode='max', verbose=1, restore_best_weights = True)\n",
    "\n",
    "# K-fold Cross Validation model \n",
    "'''设置交叉验证的次数'''\n",
    "num_folds=2\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "model.compile(\n",
    "optimizer=sgd2, \n",
    "loss= keras.losses.CategoricalCrossentropy(),\n",
    "metrics=['acc'])\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    history = model.fit_generator(generator=get_train_batch_2D(inputs[train],targets[train],8), \n",
    "        steps_per_epoch=len(train_data), \n",
    "        epochs=200,\n",
    "        shuffle=True,\n",
    "        validation_data=get_train_batch_2D(inputs[test],targets[test],16),  \n",
    "        validation_steps=len(test_data),\n",
    "        callbacks=[checkpoint,keras.callbacks.TensorBoard(log_dir=\"./log/2D2\",histogram_freq=1,write_graph=True,write_images=True,update_freq='batch')]\n",
    "        ) \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 绘制训练 & 验证的准确率值\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5保存内容"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存训练集测试集划分的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=np.save(train_data)\n",
    "train_data=np.save(test_data)\n",
    "train_data=np.save(train_label)\n",
    "train_data=np.save(test_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"425new-0.9-0.88\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
